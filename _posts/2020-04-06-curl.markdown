---
permalink: /curl/
layout: post
title:  "CURL: Contrastive Unsupervised Representations for Reinforcement Learning"
date:   2020-04-06 11:10:11 -0800
image: /images/curl/curl_img.png
categories: research
affiliation: UC Berkeley, BAIR
authors: "<b>Michael Laskin*</b>, Aravind Srinivas*, Pieter Abbeel"
venue: "In Submission"
code: https://github.com/MishaLaskin/curl
arxiv: https://arxiv.org/abs/2004.04136
equal: '*'

---


This work aims to answer the following question - can pixel-based RL be as efficient as RL from coordinate state? Traditionally, it has been widely assumed that pixel-based RL is data inefficient, often taking 100M+ interaction steps to solve benchmark tasks like Atari games. On the contrary, we show for the first time that the answer is yes. 









We present CURL: Contrastive Unsupervised Representations for Reinforcement Learning. CURL extracts high-level features from raw pixels using contrastive learning and performs off-policy control on top of the extracted features. CURL outperforms prior pixel-based methods, both model-based and model-free, on complex tasks in the DeepMind Control Suite and Atari Games showing 2.8x and 1.6x performance gains respectively at the 100K interaction steps benchmark. On the DeepMind Control Suite, CURL is the first image-based algorithm to nearly match the sample-efficiency and performance of methods that use state-based features.

<center>
<img src="/images/curl/curl_diagram.png" alt="drawing" style="width:80%;"/>
</center>


## Method 

CURL learns contrastive representations jointly with the RL objective. The representation learning is done as an auxiliary task that can be coupled to any model-free RL algorithm. In our paper, we combine contrastive representation learning with two state of the art algorithms (i) Soft Actor Critic (SAC) for continuous control and (ii) Rainbow DQN for discrete control. Contrastive representations are learned by specifying an anchor observation, and then maximizing / minimizing agreement between positive / negative pairs through Noise Contrastive Estimation. A high-level diagram of CURL is shown above; for more details refer to the paper.

## Results

<center>
<div>
<iframe width="560" height="315" src="https://www.youtube.com/embed/a6SyIg4HrbQ" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
</div>
</center>
(1) CURL matches the data-efficiency of state-based SAC on most DeepMind control tasks.

<!--<center>
<img src="/images/curl/bair_blog_curl_dmc.png" alt="drawing" style="width:80%;"/>
</center>-->

(2) CURL achieves state-of-the-art median scores at 500k frames on DeepMind control environments that are extensively benchmarked by competing baselines - across both model-free and model-based methods. At the 500k frame benchmark, CURL matches median state-based performance.

<center>
<img src="/images/curl/curl_bair_dmc.png" alt="drawing" style="width:80%;"/>
</center>

(3) CURL achieves state-of-the-art median scores across 26 Atari games at the 100k frame benchmark first proposed by the authors of SimPLe.

<center>
<img src="/images/curl/curl_bair_atari.png" alt="drawing" style="width:80%;"/>
</center>


## BibTex
<pre>
@unpublished{laskin_srinivas2020curl,
  title={CURL: Contrastive Unsupervised Representations for Reinforcement Learning},
  author={Laskin, Michael and Srinivas, Aravind and Abbeel, Pieter},
  note={arXiv:2003.06417}
}
</pre>


